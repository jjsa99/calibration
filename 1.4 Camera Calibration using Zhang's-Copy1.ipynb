{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script intends to calibrate a camera using an object.\n",
    "For this implementation we will use the Zhang's calibration method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zhang's Method\n",
    "Comparing to the DLT method, the Zhang method only calculate the intrinsic parameters. We instead only need to find 5 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the 2D and 3D coordinates\n",
    "This is example is not completely right since we need more than 3 diferent views to estimate H using Zhang's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#worldcoo = np.array([ (0,0,0), (0,28,0), (56,0,0), (56,28,0), (56,84,0), (84,84,0), (112,56,0),\n",
    "#             (112,84,0), (84,56,0), (84,112,0), (0,28,28), (0,28,56), (0,56,28), (0,56,56), \n",
    "#             (0,56,84), (0,56,112), (0,112,0), (0,112,28), (0,112,56), (0,112,84), (0,112,112) \n",
    "#           ])\n",
    "\n",
    "#imagecoo = np.array([ (1549, 1599), (1547, 1763), (1797, 1625), (1793, 1807), (1785, 2156), (1918, 2196),\n",
    "#            (2069, 2051), (2061, 2233), (1928, 2015), (1915, 2366), (1413, 1781), (1280, 1807),\n",
    "#             (1415, 1958), (1283, 1981), (1139, 2013), (990, 2041), (1541, 2251), (1420, 2287),\n",
    "#             (1292, 2320), (1149, 2356), (1005, 2401)\n",
    "#           ])\n",
    "#print(\"World coordinate have : \"+str(worldcoo.shape)+ \" dimensions\\n\")\n",
    "#print(\"Image coordinate have : \"+str(imagecoo.shape)+ \" dimensions\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to **remove the Z coordinate** from the World coordinate since we are using the chessboard calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worldcoo = worldcoo[:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize matrix\n",
    "Normalization of input data. To improve numerical stability of the calculations, it is recommended to normalize both 2D point sets X and x before performing the homography estimation. Burger[pag.14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing a given 2D point set is accomplished by shifting and scaling all points such that the centroid od the \n",
    "# transformed set is aligned with the origin and its diameter has a predefined size.\n",
    "# There are various methods in the literature to calculate the normalization. In this case, the method used is \n",
    "# applied scaling non-unformly in x- and y- direction such that the variances along both axis get normalized. Burger[appendix B, pag 46]\n",
    "def matrix_normalization(data):\n",
    "    \"\"\"\n",
    "       Args:\n",
    "          data: Nx2 stack of data points\n",
    "        Returns:\n",
    "          The normalization matrix\n",
    "    \"\"\"\n",
    "    if data.ndim != 2 or data.shape[-1] != 2:\n",
    "        raise ValueError('Dataset must be a collection of 2D points')\n",
    "\n",
    "    x, y = data[:, 0], data[:, 1]\n",
    "\n",
    "    N = data.shape[0]\n",
    "\n",
    "    x_mean, y_mean = x.mean(), y.mean()\n",
    "    x_var, y_var = x.var(), y.var()\n",
    "    \n",
    "    # Form rescaling matrix so that data points will lie\n",
    "    # sqrt(2) from the origin on average.\n",
    "    s_x, s_y = np.sqrt(2. / x_var), np.sqrt(2. / y_var)\n",
    "    \n",
    "    norm_matrix = np.array([[s_x,  0., -s_x * x_mean],\n",
    "                            [ 0., s_y, -s_y * y_mean],\n",
    "                            [ 0.,  0.,            1.]])\n",
    "\n",
    "    return norm_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Homography estimation with the DLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Solving homogeneous systems of linear equations: **SVD**\n",
    "**goal : find the homography matrix (H)** \n",
    "- Normalization matrix\n",
    "- Apply the matrix to the coordinates\n",
    "- Homogenous coordinates transformation\n",
    "- Having a system M*h = , we apply SVD(M). \n",
    "- Denormalize the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography_matrix(imagecoo,worldcoo):\n",
    "    # get the shape of the matrix\n",
    "    worldm, worldn = worldcoo.shape\n",
    "    imagem, imagen = imagecoo.shape\n",
    "\n",
    "    homo_world = np.append(worldcoo,np.ones((worldm,1)),axis = 1)\n",
    "    homo_image = np.append(imagecoo,np.ones((imagem,1)),axis = 1)\n",
    "\n",
    "\n",
    "    # world coordinate normalization\n",
    "    X_matrix_norm = matrix_normalization(worldcoo)\n",
    "    # image coordinate normalization\n",
    "    x_matrix_norm = matrix_normalization(imagecoo)\n",
    "    \n",
    "    # Normalize the coordinates\n",
    "    world_norm = np.dot(homo_world,X_matrix_norm.T)\n",
    "    image_norm = np.dot(homo_image,x_matrix_norm.T)\n",
    "\n",
    "    #2D DLT\n",
    "    X, Y, x, y = world_norm[:,0],world_norm[:,1], image_norm[:,0], image_norm[:,1]\n",
    "\n",
    "    A = np.zeros((worldm * 2, 9))\n",
    "\n",
    "    M_x = np.zeros((worldm, 9))\n",
    "    M_x[:, 0] = -X\n",
    "    M_x[:, 1] = -Y\n",
    "    M_x[:, 2] = -1.\n",
    "    M_x[:, 6] =  x * X\n",
    "    M_x[:, 7] =  x * Y\n",
    "    M_x[:, 8] =  x\n",
    "\n",
    "    M_y = np.zeros((worldm, 9))\n",
    "    M_y[:, 3] = -X\n",
    "    M_y[:, 4] = -Y\n",
    "    M_y[:, 5] = -1.\n",
    "    M_y[:, 6] =  y * X\n",
    "    M_y[:, 7] =  y * Y\n",
    "    M_y[:, 8] =  y\n",
    "\n",
    "    # Note that all x-constraints precede all y-constraints for convenience of \n",
    "    # representation.\n",
    "    A[:worldm] = M_x\n",
    "    A[worldm:] = M_y\n",
    "\n",
    "    U, S, V = np.linalg.svd(A)\n",
    "    # get the min Singular value\n",
    "    idx = np.argmin(S)\n",
    "    H = V[idx].reshape(3,3)\n",
    "    \n",
    "    # Denormalize the coordinates\n",
    "    H = np.dot(np.dot(np.linalg.inv(x_matrix_norm), H), X_matrix_norm)\n",
    "    #print(\"Homography Matrix: \\n\"+str(H))\n",
    "    return H\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the Corner information of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the corner of the checkerboard\n",
    "+ With 9 images, each one with 48 image points\n",
    "+ The checkerboard has 25mm between corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images\n",
    "n_imgs = 9\n",
    "# pattern size\n",
    "patternsize= (6,8)\n",
    "#distance between squares(in mm)\n",
    "dist = 25\n",
    "\n",
    "# specified number of iterations are completed.\n",
    "criteria = (cv2.TERM_CRITERIA_EPS +\n",
    "            cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Vector for 3D points\n",
    "threedpoints = []\n",
    " \n",
    "# Vector for 2D points\n",
    "twodpoints = []\n",
    "\n",
    "#3D points real world coordinates( static -> chessboard)\n",
    "# create a matrix of zeros for 48 points , each with 3 coordinates\n",
    "world_coo = np.zeros((1, patternsize[0]* patternsize[1],3), np.float32)\n",
    "world_coo[:, :, :2] = np.mgrid[0:patternsize[0], 0:patternsize[1]].T.reshape(-1, 2)\n",
    "# Transform coordinates in mm\n",
    "world_coo = world_coo*dist\n",
    "\n",
    "#prev_img_shape = None\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    \n",
    "    name = (\"Chessboard_real_\"+ str(i+1)+\".jpeg\")\n",
    "    #Import the image\n",
    "    img = cv2.imread(name)\n",
    "    # convert it to gray scale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    retval, corners= cv2.findChessboardCorners(gray,patternsize,cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK +cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    \n",
    "    if(retval == True):\n",
    "        threedpoints.append(world_coo)\n",
    "\n",
    "        # Refining pixel coordinates or given 2d points.\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria).reshape(48,2)\n",
    "\n",
    "        twodpoints.append(corners2)\n",
    "        # Draw and display the corners\n",
    "        image = cv2.drawChessboardCorners(img,patternsize,corners2,retval)\n",
    "        plt.imshow(image)\n",
    "        #plt.show()\n",
    "\n",
    "# image coordinates and world coordinates for the diferent images( the world coordinates are always the same)\n",
    "imagecoo = np.asarray(twodpoints)\n",
    "worldcoo = np.asarray(threedpoints) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list to store the homographies\n",
    "H = np.zeros((n_imgs,3,3))\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    im = imagecoo[i][:][:].reshape(48,2)\n",
    "    wo = worldcoo[0][:].reshape(48,3)\n",
    "    # remove the Z coordinate\n",
    "    wo = wo[:,:2]\n",
    "    H[i,:] = homography_matrix(im,wo)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Determining the intrinsic camera parameters\n",
    "Use the computed homographies to calculate the intrisic matrix \\\n",
    "Since H has **8DoF, it's needed >= 4 points to estimate the homography**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Generate $V_{pq}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_v(H_stack, i, j):\n",
    "    \"\"\"Generate intrinsic orthogonality constraints. See Zhang pg. 6 for\n",
    "       details.\n",
    "    \"\"\" \n",
    "    M = H_stack.shape[0]\n",
    "\n",
    "    v_ij = np.zeros((M, 6))\n",
    "    v_ij[:, 0] = H_stack[:, 0, i] * H_stack[:, 0, j]\n",
    "    v_ij[:, 1] = H_stack[:, 0, i] * H_stack[:, 1, j] + H_stack[:, 1, i] * H_stack[:, 0, j]\n",
    "    v_ij[:, 2] = H_stack[:, 1, i] * H_stack[:, 1, j]\n",
    "    v_ij[:, 3] = H_stack[:, 2, i] * H_stack[:, 0, j] + H_stack[:, 0, i] * H_stack[:, 2, j]\n",
    "    v_ij[:, 4] = H_stack[:, 2, i] * H_stack[:, 1, j] + H_stack[:, 1, i] * H_stack[:, 2, j]\n",
    "    v_ij[:, 5] = H_stack[:, 2, i] * H_stack[:, 2, j]\n",
    "\n",
    "    return v_ij\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Compute the intrisic Matrix.\n",
    "We need >= 3 homographies for a full 5-parameter intrinsic matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrisicmatrix(H):\n",
    "    M = len(H)\n",
    "\n",
    "    V01 = generate_v(H,0,1)\n",
    "    V00 = generate_v(H,0,0)\n",
    "    V11 = generate_v(H,1,1)\n",
    "\n",
    "    # vq(H) is a 6 dimensional row vector obtained from the estimated Homography H\n",
    "    V = np.zeros((2*M,6))\n",
    "\n",
    "    V[:M] = V01\n",
    "    V[M:] = V00-V11\n",
    "\n",
    "    # Use SVD to solve the homogeneous system Vb = 0( In this case we have a overdetermined system)\n",
    "    U, S, Vh = np.linalg.svd(V)\n",
    "    idx = np.argmin(S)\n",
    "    b = Vh[idx]\n",
    "\n",
    "\n",
    "    # camera intrinsics( Zhang creates a new matrix which is symmetric and composed of only 6 distinct quantities)\n",
    "    B0, B1, B2, B3, B4, B5 = b\n",
    "\n",
    "    # B = A^(-T)*A^(-1)\n",
    "    B = np.array([[B0,B1,B3],\n",
    "                  [B1,B2,B4],\n",
    "                  [B3,B4,B5]]);\n",
    "\n",
    "    w = (B0*B2*B5) - ((B1**2)*(B5))-((B0)*(B4**2))+(2*B1*B3*B4)-((B2)*(B3**2))\n",
    "    d = B0*B2 - B1**2\n",
    "\n",
    "    v0 = (B[0,1] * B[0,2] - B[0,0] * B[1,2]) / (B[0,0] * B[1,1] - B[0,1] * B[0,1])\n",
    "    lambda_ = B[2,2] - (B[0,2] * B[0,2] + v0 * (B[0,1] * B[0,2] - B[0,0] * B[1,2])) / B[0,0]\n",
    "    alpha = np.sqrt(lambda_ / B[0,0])\n",
    "    beta = np.sqrt(lambda_ * B[0,0] / (B[0,0] * B[1,1] - B[0,1] * B[0,1]))\n",
    "    gamma = -B[0,1] * alpha * alpha * beta / lambda_\n",
    "    u0 = gamma * v0 / beta - B[0,2] * alpha * alpha / lambda_\n",
    "\n",
    "\n",
    "    # Reconstitute intrinsic matrix\n",
    "    K = np.array([[alpha, gamma, u0],\n",
    "                  [   0,  beta, v0],\n",
    "                  [   0,    0, 1]])\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[777.87199322   2.64055711 503.10016721]\n",
      " [  0.         779.14557997 372.34910923]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "K = intrisicmatrix(H)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recover the extrinsic parameters\n",
    "After retrieving the intrinsic matrix, we use both the intrinsic and extrinsic matrix to calculate the corresponding extrinsic matrix( Burger, pag 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_extrinsics(H,K):\n",
    "    # obtain the column vectores from the homography matrix\n",
    "    h0,h1,h2 = H[:,0],H[:,1],H[:,2]\n",
    "    \n",
    "    K_inv = np.linalg.inv(K)\n",
    "    \n",
    "    #norm the term\n",
    "    lambda_ = 1. / np.linalg.norm(np.dot(K_inv, h0))\n",
    "    \n",
    "    r0 = (lambda_ * np.dot(K_inv,h0))\n",
    "    r1 = (lambda_ * np.dot(K_inv,h1))\n",
    "    t =  (lambda_ * np.dot(K_inv,h2)).reshape(3,1)\n",
    "\n",
    "    # since R must be orthogonal\n",
    "    r2 = np.cross(r0,r1)\n",
    "    \n",
    "    # rotation matrix reconstrution\n",
    "    R = np.vstack((r0, r1, r2)).T\n",
    "    \n",
    "    # reorthogonalize the rotation matrix( Zhang, pag 18, Append C)\n",
    "    #(The sense of \"best\" rotation matrix R is in the sense of the smallest Frobenius norm of the difference R-Q)\n",
    "    U,S,Vt = np.linalg.svd(R)\n",
    "    R_ortho = np.dot(U,Vt)\n",
    "    extrinsics = np.hstack((R_ortho, t))\n",
    "    \n",
    "    return extrinsics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Compute the extrinsics based on the intrisincs already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform coordinates to euclidean\n",
    "def to_euclidean(homogeneous_coordinate):\n",
    "    euclidean = homogeneous_coordinate[:,:]/(homogeneous_coordinate[:,-1][:,np.newaxis])\n",
    "\n",
    "    return euclidean[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform coordinates to homogenous\n",
    "def to_homogeneous(euclideancoo):\n",
    "\n",
    "    if euclideancoo.ndim != 2 or euclideancoo.shape[-1] != 2:\n",
    "        raise ValueError('Stacked vectors must be 2D inhomogeneous')\n",
    "    \n",
    "    M,N = euclidean.shape\n",
    "    homogeneous = np.hstack((euclideancoo),np.ones((M,1)))\n",
    "    \n",
    "    return homogeneous\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrinsic_matrices = []\n",
    "\n",
    "for h, Homograph in enumerate(H):\n",
    "    E = extract_extrinsics(Homograph,K)\n",
    "    extrinsic_matrices.append(E)\n",
    "    \n",
    "    # Projection matrix\n",
    "    P = np.dot(K,E)\n",
    "    # homogeneous world coordinates\n",
    "    homo_world = np.append(worldcoo[0][:].reshape(48,3),np.ones((48,1)),axis = 1) \n",
    "\n",
    "    predicted = np.dot(homo_world,P.T)\n",
    "    \n",
    "    #print(to_euclidean(predicted))\n",
    "    #print(imagecoo)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

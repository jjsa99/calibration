{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8.1 Stereo retification \n",
    "This script intends to address the question: \"how many different orientations are needed to have an acceptable 3D error?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vscode = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(vscode == 1):\n",
    "    # for vscode\n",
    "    %matplotlib qt\n",
    "else:\n",
    "    # for jupyter notebook\n",
    "    from mpl_toolkits.mplot3d import axes3d\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    %matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from typing import Sequence\n",
    "from calib_lib import *\n",
    "DECIMALS = 2  # how many decimal places to use in print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 16                                       # focal length( in mm )\n",
    "image_size = np.array([11,7])               # sensor size(in mm)\n",
    "PX= image_size[0]/2.0                       # principal point x-coordinate\n",
    "PY= image_size[1]/2.0                       # principal point y-coordinate\n",
    "IMAGE_HEIGTH = image_size[1]\n",
    "IMAGE_WIDTH = image_size[0]\n",
    "THETA_X = 0                                 # roll angle\n",
    "THETA_Y = 0                                 # pitch angle\n",
    "THETA_Z = 0                         # yaw angle\n",
    "\n",
    "\n",
    "# camera Right\n",
    "THETA_X_R = 0                                 # roll angle\n",
    "THETA_Y_R = 0                                 # pitch angle\n",
    "THETA_Z_R= 0                                 # yaw angle\n",
    "# camera Left\n",
    "THETA_X_L = 0                                 # roll angle\n",
    "THETA_Y_L = 0                                 # pitch angle\n",
    "THETA_Z_L= 0                                 # yaw angle\n",
    "\n",
    "C_L = np.array([0,0,0])                     # camera centre\n",
    "C_R = np.array([500,0,0])\n",
    "\n",
    "chess_dimx,chess_dimy = (13,9)\n",
    "chess_sq_size = 44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create chessboard and translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translst= []\n",
    "\n",
    "xrange = np.linspace(-6000,6000,10)\n",
    "yrange = np.linspace(-4000,4000,10)\n",
    "zrange = ([20000])\n",
    "for z in zrange:\n",
    "    for x in  xrange:\n",
    "        for y in yrange:\n",
    "            translst.append([x,y,z])\n",
    "            \n",
    "len(translst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 140, 3)\n"
     ]
    }
   ],
   "source": [
    "# chessboard print\n",
    "chess_pts = []\n",
    "world_pts = create_chessboard(chess_dimx,chess_dimy,chess_sq_size)\n",
    "rotangles = [[0,0,0],[np.pi/4,0,np.pi/2],[0,np.pi/4,np.pi/2],[0,np.pi/4,-np.pi/2],[np.pi/4,0,-np.pi/2]]\n",
    "\n",
    "for i in range(len(translst)):\n",
    "    for j in range(len(rotangles)):    \n",
    "        chess_pts.append(get_chessboard_rot_trans(world_pts,rotangles[j][0],rotangles[j][1],rotangles[j][2],translst[i][0],translst[i][1],translst[i][2]))\n",
    "\n",
    "chess_pts_arr = np.array(chess_pts)\n",
    "print(chess_pts_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Obtain 2D correspondence\n",
    "\"The technique only requires the camera to observw a planar pattern shown at a few( at least two) different orientations\"\\\n",
    "In this example, it is shown 3 different orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n",
      "(140, 3)\n",
      "World points:  (1, 140, 3)\n",
      "Image points:  (500, 140, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pattern_size_x,pattern_size_y = (chess_dimx,chess_dimy)\n",
    "\n",
    "X_pattern = np.linspace(0, pattern_size_x,pattern_size_x + 1)*chess_sq_size\n",
    "Y_pattern = np.linspace(0, pattern_size_y,pattern_size_y + 1)*chess_sq_size\n",
    "zdata = np.zeros((pattern_size_x + 1,pattern_size_y + 1))\n",
    "xdata, ydata = np.meshgrid(X_pattern, Y_pattern)\n",
    "\n",
    "xdata_ = xdata.flatten()\n",
    "ydata_ = ydata.flatten()\n",
    "zdata_ = zdata.flatten()\n",
    "\n",
    "# homogeneous coordinates\n",
    "world_pts =([xdata_,ydata_,zdata_])\n",
    "world_pts_ = np.array(world_pts).T\n",
    "\n",
    "world_pts_arr = np.zeros((chess_pts_arr.shape[0],3),np.float32)\n",
    "print(world_pts_arr.shape)\n",
    "print(world_pts_.shape)\n",
    "world_pts_arr = world_pts_\n",
    "\n",
    "world_pts_arr = world_pts_arr.reshape(1,(pattern_size_x+1)*(pattern_size_y+1),3)\n",
    "\n",
    "x_lst_R = []\n",
    "x_lst_L = []\n",
    "for i in range(chess_pts_arr.shape[0]):\n",
    "    x_arr_R, X_arr_R, E_R, K_R, P_R = get_image_points(chess_pts_arr[i,:,:],PX,PY,thetax= 0.0,thetay = 0.0,thetaz = 0.0,trans_x= -C_R[0],trans_y= -C_R[1],trans_z= -C_R[2],F = F)\n",
    "    x_arr_L, X_arr_L, E_L, K_L, P_L = get_image_points(chess_pts_arr[i,:,:],PX,PY,thetax= 0.0,thetay = 0.0,thetaz = 0.0,trans_x= -C_L[0],trans_y= -C_L[1],trans_z= -C_L[2],F = F)\n",
    "    \n",
    "    x_lst_R.append(x_arr_R)\n",
    "    x_lst_L.append(x_arr_L)\n",
    "\n",
    "x_zhang_R = np.array(x_lst_R,np.float32).reshape((len(rotangles)*len(translst),(pattern_size_x+1)*(pattern_size_y+1),2))\n",
    "x_zhang_L = np.array(x_lst_L,np.float32).reshape((len(rotangles)*len(translst),(pattern_size_x+1)*(pattern_size_y+1),2))\n",
    "\n",
    "world_pts_arr = np.array(world_pts_arr,np.float32).reshape((1,(pattern_size_x+1)*(pattern_size_y+1),3))\n",
    "\n",
    "print(\"World points: \",world_pts_arr.shape)\n",
    "print(\"Image points: \",x_zhang_L.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,11))\n",
    "\n",
    "nr_photo = 0\n",
    "ax_L = fig.add_subplot(121)\n",
    "ax_L.plot(x_zhang_L[:,:,0],x_zhang_L[:,:,1], color = 'r',ls = \"None\", marker = \".\", label = 'Left')\n",
    "ax_L.set_xlabel(\"X axis\")\n",
    "ax_L.set_ylabel(\"Y axis\")\n",
    "ax_L.grid()\n",
    "#ax_L.legend()\n",
    "ax_L.set_xlim([0,image_size[0]])\n",
    "ax_L.set_ylim([0,image_size[1]])\n",
    "\n",
    "ax_R = fig.add_subplot(122)\n",
    "ax_R.plot(x_zhang_R[:,:,0],x_zhang_R[:,:,1], color = 'r',ls = \"None\", marker = \".\", label = 'Right')\n",
    "ax_R.set_xlabel(\"X axis\")\n",
    "ax_R.set_ylabel(\"Y axis\")\n",
    "ax_R.grid()\n",
    "#ax_R.legend()\n",
    "ax_R.set_xlim([0,image_size[0]])\n",
    "ax_R.set_ylim([0,image_size[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_pts_arr_ = np.zeros((len(rotangles)*len(translst),world_pts_arr.shape[0],world_pts_arr.shape[1],world_pts_arr.shape[2]))\n",
    "for i in range(world_pts_arr_.shape[0]):\n",
    "    world_pts_arr_[i,:,:,:] = world_pts_arr\n",
    "world_pts_arr_ = np.array(world_pts_arr_,np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 140, 2)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_zhang_R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. mono camera calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chess_pts_arr = np.array(chess_pts_arr,np.float32).reshape((3,(pattern_size_x+1)*(pattern_size_y+1),3))\n",
    "#print(chess_pts_arr.shape)\n",
    "ret_R, mtx_R, dist_R, rvecs_R, tvecs_R = cv2.calibrateCamera(world_pts_arr_, x_zhang_R, (image_size[0],image_size[1]), None, None)\n",
    "ret_L, mtx_L, dist_L, rvecs_L, tvecs_L = cv2.calibrateCamera(world_pts_arr_, x_zhang_L, (image_size[0],image_size[1]), None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Stereo calibration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_flags = cv2.CALIB_FIX_INTRINSIC\n",
    "\n",
    "# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# Hence intrinsic parameters are the same \n",
    "\n",
    "criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retS, new_mtxL, distL, new_mtxR, distR, Rot, Trns, Emat, Fmat = cv2.stereoCalibrate(world_pts_arr_, x_zhang_L, x_zhang_R, mtx_L, dist_L, mtx_R, dist_R, (image_size[0],image_size[1]), criteria_stereo, stereo_flags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.213222840715945e-07"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.00000127  0.          5.49999988  0.        ]\n",
      " [ 0.         16.00000127  3.50000033  0.        ]\n",
      " [ 0.          0.          1.          0.        ]]\n",
      "[[ 1.60000013e+01  0.00000000e+00  5.49999988e+00 -8.00000115e+03]\n",
      " [ 0.00000000e+00  1.60000013e+01  3.50000033e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "R1,R2,P_L_est,P_R_est,Q,roi_left,roi_right = cv2.stereoRectify(new_mtxL, ret_L, new_mtxR, ret_R, (image_size[0],image_size[1]), Rot, Trns,flags = cv2.CALIB_ZERO_DISPARITY)\n",
    "print(P_L_est)\n",
    "print(P_R_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_R = np.array([7.45678948, 1.00184743])\n",
    "x_L = np.array([7.79416698, 1.00184743])\n",
    "XestOpenCV = cv2.triangulatePoints(P_L_est,P_R_est, x_L, x_R) \n",
    "Xoriginal = cv2.triangulatePoints(P_L, P_R, x_L, x_R) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.39999997e+03],\n",
       "       [-3.70231057e+03],\n",
       "       [ 2.37123104e+04],\n",
       "       [ 1.00000000e+00]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xoriginal /= Xoriginal[-1]\n",
    "Xoriginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.40000036e+03],\n",
       "       [-3.70231130e+03],\n",
       "       [ 2.37123138e+04],\n",
       "       [ 1.00000000e+00]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XestOpenCV /= XestOpenCV[-1]\n",
    "XestOpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0045202544592939375"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estError = np.sum(np.abs(XestOpenCV-Xoriginal))\n",
    "estError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a1e11f5a9d6a633cc6edcb944e6a353ce0832dacf7c6ded8f94bd883e52ad00"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

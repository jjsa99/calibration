{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is an extension of the previous. In this one, it's added non-linear refinement of the homography matrix using LM\\\n",
    "For this implementation we will use the Zhang's calibration method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#for LM method\n",
    "from scipy.optimize import curve_fit\n",
    "#matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zhang's Method\n",
    "Comparing to the DLT method, the Zhang method only calculate the intrinsic parameters. We instead only need to find 5 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the 2D and 3D coordinates\n",
    "This is example is not completely right since we need more than 3 diferent views to estimate H using Zhang's method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#worldcoo = np.array([ (0,0,0), (0,28,0), (56,0,0), (56,28,0), (56,84,0), (84,84,0), (112,56,0),\n",
    "#             (112,84,0), (84,56,0), (84,112,0), (0,28,28), (0,28,56), (0,56,28), (0,56,56), \n",
    "#             (0,56,84), (0,56,112), (0,112,0), (0,112,28), (0,112,56), (0,112,84), (0,112,112) \n",
    "#           ])\n",
    "\n",
    "#imagecoo = np.array([ (1549, 1599), (1547, 1763), (1797, 1625), (1793, 1807), (1785, 2156), (1918, 2196),\n",
    "#            (2069, 2051), (2061, 2233), (1928, 2015), (1915, 2366), (1413, 1781), (1280, 1807),\n",
    "#             (1415, 1958), (1283, 1981), (1139, 2013), (990, 2041), (1541, 2251), (1420, 2287),\n",
    "#             (1292, 2320), (1149, 2356), (1005, 2401)\n",
    "#           ])\n",
    "#print(\"World coordinate have : \"+str(worldcoo.shape)+ \" dimensions\\n\")\n",
    "#print(\"Image coordinate have : \"+str(imagecoo.shape)+ \" dimensions\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to **remove the Z coordinate** from the World coordinate since we are using the chessboard calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worldcoo = worldcoo[:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalize matrix\n",
    "Normalization of input data. To improve numerical stability of the calculations, it is recommended to normalize both 2D point sets X and x before performing the homography estimation. Burger[pag.14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing a given 2D point set is accomplished by shifting and scaling all points such that the centroid od the \n",
    "# transformed set is aligned with the origin and its diameter has a predefined size.\n",
    "# There are various methods in the literature to calculate the normalization. In this case, the method used is \n",
    "# applied scaling non-unformly in x- and y- direction such that the variances along both axis get normalized. Burger[appendix B, pag 46]\n",
    "def matrix_normalization(data):\n",
    "    \"\"\"\n",
    "       Args:\n",
    "          data: Nx2 stack of data points\n",
    "        Returns:\n",
    "          The normalization matrix\n",
    "    \"\"\"\n",
    "    if data.ndim != 2 or data.shape[-1] != 2:\n",
    "        raise ValueError('Dataset must be a collection of 2D points')\n",
    "\n",
    "    x, y = data[:, 0], data[:, 1]\n",
    "\n",
    "    N = data.shape[0]\n",
    "\n",
    "    x_mean, y_mean = x.mean(), y.mean()\n",
    "    x_var, y_var = x.var(), y.var()\n",
    "    \n",
    "    # Form rescaling matrix so that data points will lie\n",
    "    # sqrt(2) from the origin on average.\n",
    "    s_x, s_y = np.sqrt(2. / x_var), np.sqrt(2. / y_var)\n",
    "    \n",
    "    norm_matrix = np.array([[s_x,  0., -s_x * x_mean],\n",
    "                            [ 0., s_y, -s_y * y_mean],\n",
    "                            [ 0.,  0.,            1.]])\n",
    "\n",
    "    return norm_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the Corner information of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Finding the corner of the checkerboard\n",
    "+ With 9 images, each one with 48 image points\n",
    "+ The checkerboard has 25mm between corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images\n",
    "n_imgs = 9\n",
    "# pattern size\n",
    "#patternsize= (10,8)\n",
    "patternsize= (6,8)\n",
    "#distance between squares(in mm)\n",
    "dist = 25\n",
    "\n",
    "# specified number of iterations are completed.\n",
    "criteria = (cv2.TERM_CRITERIA_EPS +\n",
    "            cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Vector for 3D points\n",
    "threedpoints = []\n",
    " \n",
    "# Vector for 2D points\n",
    "twodpoints = []\n",
    "\n",
    "#3D points real world coordinates( static -> chessboard)\n",
    "# create a matrix of zeros for 48 points , each with 3 coordinates\n",
    "world_coo = np.zeros((1, patternsize[0]* patternsize[1],3), np.float32)\n",
    "world_coo[:, :, :2] = np.mgrid[0:patternsize[0], 0:patternsize[1]].T.reshape(-1, 2)\n",
    "# Transform coordinates in mm\n",
    "world_coo = world_coo*dist\n",
    "\n",
    "#prev_img_shape = None\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    \n",
    "    #Import the image\n",
    "    #img = cv2.imread((\"Research/BinoCameraCalibrate-master/BinoCameraCalibrate/Calibration_Image_Camera/Image_l\"+str(i+1)+\".jpg\"))\n",
    "    name = (\"Chessboard_real_\"+ str(i+1)+\".jpeg\")\n",
    "    img = cv2.imread(name)\n",
    "    # convert it to gray scale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    retval, corners= cv2.findChessboardCorners(gray,patternsize,cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK +cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    \n",
    "    if(retval == True):\n",
    "        threedpoints.append(world_coo)\n",
    "\n",
    "        # Refining pixel coordinates or given 2d points.\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria).reshape(patternsize[0]*patternsize[1],2)\n",
    "\n",
    "        twodpoints.append(corners2)\n",
    "        # Draw and display the corners\n",
    "        image = cv2.drawChessboardCorners(img,patternsize,corners2,retval)\n",
    "        plt.imshow(image)\n",
    "        #plt.show()\n",
    "\n",
    "# image coordinates and world coordinates for the diferent images( the world coordinates are always the same)\n",
    "imagecoo = np.asarray(twodpoints)\n",
    "worldcoo = np.asarray(threedpoints) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Homography estimation with the DLT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Solving homogeneous systems of linear equations: **SVD**\n",
    "**goal : find the homography matrix (H)** \n",
    "- Normalization matrix\n",
    "- Apply the matrix to the coordinates\n",
    "- Homogenous coordinates transformation\n",
    "- Having a system M*h = , we apply SVD(M). \n",
    "- Denormalize the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform coordinates to euclidean\n",
    "def to_euclidean(homogeneous_coordinate):\n",
    "    euclidean = homogeneous_coordinate[:,:]/(homogeneous_coordinate[:,-1][:,np.newaxis])\n",
    "\n",
    "    return euclidean[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform coordinates to homogenous\n",
    "def to_homogeneous(euclideancoo):\n",
    "\n",
    "    if euclideancoo.ndim != 2 or euclideancoo.shape[-1] != 2:\n",
    "        raise ValueError('Stacked vectors must be 2D inhomogeneous')\n",
    "    \n",
    "    M,N = euclideancoo.shape\n",
    "    homogeneous = np.hstack(((euclideancoo),np.ones((M,1))))\n",
    "    \n",
    "    return homogeneous\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography_matrix(worldcoo,imagecoo):\n",
    "    # get the shape of the matrix\n",
    "    worldm, worldn = worldcoo.shape\n",
    "    imagem, imagen = imagecoo.shape\n",
    "\n",
    "    homo_world = to_homogeneous(worldcoo) \n",
    "    homo_image = to_homogeneous(imagecoo)\n",
    "\n",
    "    # world coordinate normalization\n",
    "    X_matrix_norm = matrix_normalization(worldcoo)\n",
    "    # image coordinate normalization\n",
    "    x_matrix_norm = matrix_normalization(imagecoo)\n",
    "    \n",
    "    # Normalize the coordinates\n",
    "    world_norm = np.dot(homo_world,X_matrix_norm.T)\n",
    "    image_norm = np.dot(homo_image,x_matrix_norm.T)\n",
    "\n",
    "    #2D DLT\n",
    "    X, Y, x, y = world_norm[:,0],world_norm[:,1], image_norm[:,0], image_norm[:,1]\n",
    "\n",
    "    A = np.zeros((worldm * 2, 9))\n",
    "\n",
    "    M_x = np.zeros((worldm, 9))\n",
    "    M_x[:, 0] = -X\n",
    "    M_x[:, 1] = -Y\n",
    "    M_x[:, 2] = -1.\n",
    "    M_x[:, 6] =  x * X\n",
    "    M_x[:, 7] =  x * Y\n",
    "    M_x[:, 8] =  x\n",
    "\n",
    "    M_y = np.zeros((worldm, 9))\n",
    "    M_y[:, 3] = -X\n",
    "    M_y[:, 4] = -Y\n",
    "    M_y[:, 5] = -1.\n",
    "    M_y[:, 6] =  y * X\n",
    "    M_y[:, 7] =  y * Y\n",
    "    M_y[:, 8] =  y\n",
    "\n",
    "    # Note that all x-constraints precede all y-constraints for convenience of \n",
    "    # representation.\n",
    "    A[:worldm] = M_x\n",
    "    A[worldm:] = M_y\n",
    "\n",
    "    U, S, V = np.linalg.svd(A)\n",
    "    # get the min Singular value\n",
    "    idx = np.argmin(S)\n",
    "    H = V[idx].reshape((3,3))\n",
    "    \n",
    "    # Denormalize the coordinates\n",
    "    H = np.dot(np.dot(np.linalg.inv(x_matrix_norm), H), X_matrix_norm)\n",
    "\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 Homography matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty array to store the homographies\n",
    "H = np.zeros((n_imgs,3,3))\n",
    "# empty array to store the normalized homographies\n",
    "H_norm= np.zeros((n_imgs,3,3))\n",
    "# world coordinates\n",
    "wo = worldcoo[0][:].reshape(patternsize[0]*patternsize[1],3)\n",
    "# remove the Z coordinate\n",
    "wo = wo[:,:2]\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    im = imagecoo[i][:][:].reshape(patternsize[0]*patternsize[1],2)\n",
    "    # homography matrix\n",
    "    H[i,:] = homography_matrix(wo,im)\n",
    "    # normalized homography matrix\n",
    "    H_norm[i,:] = H[i,:]/H[i,-1,-1]\n",
    "#print(H_norm)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 Homagraphy matrix refinement\n",
    "Non-linear refiment of the homography matrix using **Levenberg-Marquardt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Aux functions\n",
    "**a) jacobian refine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jac_refine(xdata, *params):\n",
    "    \"\"\"Jacobian function for Levenberg-Marquardt refinement.\n",
    "    \"\"\"\n",
    "    h11, h12, h13, h21, h22, h23, h31, h32, h33 = params\n",
    "\n",
    "    N = xdata.shape[0] // 2\n",
    "\n",
    "    X = xdata[:N]\n",
    "    Y = xdata[N:]\n",
    "\n",
    "    J = np.zeros((N * 2, 9))\n",
    "    J_x = J[:N]\n",
    "    J_y = J[N:]\n",
    "\n",
    "    s_x = h11 * X + h12 * Y + h13\n",
    "    s_y = h21 * X + h22 * Y + h23\n",
    "    w   = h31 * X + h32 * Y + h33\n",
    "    w_sq = w**2\n",
    "\n",
    "    J_x[:, 0] = X / w\n",
    "    J_x[:, 1] = Y / w\n",
    "    J_x[:, 2] = 1. / w\n",
    "    J_x[:, 6] = (-s_x * X) / w_sq\n",
    "    J_x[:, 7] = (-s_x * Y) / w_sq\n",
    "    J_x[:, 8] = -s_x / w_sq\n",
    "\n",
    "    J_y[:, 3] = X / w\n",
    "    J_y[:, 4] = Y / w\n",
    "    J_y[:, 5] = 1. / w\n",
    "    J_y[:, 6] = (-s_y * X) / w_sq\n",
    "    J_y[:, 7] = (-s_y * Y) / w_sq\n",
    "    J_y[:, 8] = -s_y / w_sq\n",
    "\n",
    "    J[:N] = J_x\n",
    "    J[N:] = J_y\n",
    "\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Value function LM refinement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_refine(xdata, *params):\n",
    "    \"\"\"Value function for Levenberg-Marquardt refinement.\n",
    "    \"\"\"\n",
    "    h11, h12, h13, h21, h22, h23, h31, h32, h33 = params\n",
    "\n",
    "    N = xdata.shape[0] // 2\n",
    "\n",
    "    X = xdata[:N]\n",
    "    Y = xdata[N:]\n",
    "\n",
    "    x = (h11 * X + h12 * Y + h13) / (h31 * X + h32 * Y + h33)\n",
    "    y = (h21 * X + h22 * Y + h23) / (h31 * X + h32 * Y + h33)\n",
    "\n",
    "    result = np.zeros_like(xdata)\n",
    "    result[:N] = x\n",
    "    result[N:] = y\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**c) Nonlinear LS to refine linear homography estimates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_homography(H,worldcoo,imagecoo):\n",
    "    \"\"\"\n",
    "    Performs nonlinear LS to refine linear homography estimates.\n",
    "    \n",
    "    Args:\n",
    "        H : 3x3 homography matrix\n",
    "        worldcoo : Nx2 world coordinates\n",
    "        imagecoo : Nx2 image coordinates\n",
    "    Returns:\n",
    "        Refined 3x3 homography\n",
    "    \"\"\"\n",
    "    X,Y,x,y = worldcoo[:,0],worldcoo[:,1],imagecoo[:,0],imagecoo[:,1]\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    \n",
    "    h0 = H.ravel()\n",
    "\n",
    "    xdata = np.zeros(N * 2)\n",
    "    xdata[:N] = X\n",
    "    xdata[N:] = Y\n",
    "\n",
    "    ydata = np.zeros(N * 2)\n",
    "    ydata[:N] = x\n",
    "    ydata[N:] = y\n",
    "\n",
    "    # Use Levenberg-Marquardt to refine the linear homography estimate\n",
    "    popt, pcov = curve_fit(f_refine, xdata, ydata, p0=h0, jac=jac_refine)\n",
    "    h_refined = popt\n",
    "    \n",
    "    # Normalize and reconstitute homography\n",
    "    h_refined /= h_refined[-1]\n",
    "    H_refined = h_refined.reshape((3,3))\n",
    "\n",
    "    return H_refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.3 Homography matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# empty array to store the homographies\n",
    "H_refined = np.zeros((n_imgs,3,3))\n",
    "# temporary array \n",
    "H_temp = np.array((3,3))\n",
    "# world coordinates\n",
    "wo = worldcoo[0][:].reshape(patternsize[0]*patternsize[1],3)\n",
    "# remove the Z coordinate\n",
    "wo = wo[:,:2]\n",
    "\n",
    "for i in range(n_imgs):\n",
    "    im = imagecoo[i][:][:].reshape(patternsize[0]*patternsize[1],2)\n",
    "    H_temp = homography_matrix(wo,im)\n",
    "    H_refined[i,:] = refine_homography(H_temp,wo,im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Determining the intrinsic camera parameters\n",
    "Use the computed homographies to calculate the intrisic matrix \\\n",
    "Since H has **8DoF, it's needed >= 4 points to estimate the homography**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Generate $V_{pq}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_v(H_stack, i, j):\n",
    "    \"\"\"Generate intrinsic orthogonality constraints. See Zhang pg. 6 for\n",
    "       details.\n",
    "    \"\"\" \n",
    "    M = H_stack.shape[0]\n",
    "\n",
    "    v_ij = np.zeros((M, 6))\n",
    "    v_ij[:, 0] = H_stack[:, 0, i] * H_stack[:, 0, j]\n",
    "    v_ij[:, 1] = H_stack[:, 0, i] * H_stack[:, 1, j] + H_stack[:, 1, i] * H_stack[:, 0, j]\n",
    "    v_ij[:, 2] = H_stack[:, 1, i] * H_stack[:, 1, j]\n",
    "    v_ij[:, 3] = H_stack[:, 2, i] * H_stack[:, 0, j] + H_stack[:, 0, i] * H_stack[:, 2, j]\n",
    "    v_ij[:, 4] = H_stack[:, 2, i] * H_stack[:, 1, j] + H_stack[:, 1, i] * H_stack[:, 2, j]\n",
    "    v_ij[:, 5] = H_stack[:, 2, i] * H_stack[:, 2, j]\n",
    "\n",
    "    return v_ij\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Compute the intrisic Matrix.\n",
    "We need >= 3 homographies for a full 5-parameter intrinsic matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrisicmatrix(H):\n",
    "    M = len(H)\n",
    "\n",
    "    V01 = generate_v(H,0,1)\n",
    "    V00 = generate_v(H,0,0)\n",
    "    V11 = generate_v(H,1,1)\n",
    "\n",
    "    # vq(H) is a 6 dimensional row vector obtained from the estimated Homography H\n",
    "    V = np.zeros((2*M,6))\n",
    "\n",
    "    V[:M] = V01\n",
    "    V[M:] = V00-V11\n",
    "\n",
    "    # Use SVD to solve the homogeneous system Vb = 0( In this case we have a overdetermined system)\n",
    "    U, S, Vh = np.linalg.svd(V)\n",
    "    idx = np.argmin(S)\n",
    "    b = Vh[idx]\n",
    "\n",
    "\n",
    "    # camera intrinsics( Zhang creates a new matrix which is symmetric and composed of only 6 distinct quantities)\n",
    "    B0, B1, B2, B3, B4, B5 = b\n",
    "\n",
    "    # B = A^(-T)*A^(-1)\n",
    "    B = np.array([[B0,B1,B3],\n",
    "                  [B1,B2,B4],\n",
    "                  [B3,B4,B5]]);\n",
    "    \n",
    "    print(B)\n",
    "\n",
    "    w = (B0*B2*B5) - ((B1**2)*(B5))-((B0)*(B4**2))+(2*B1*B3*B4)-((B2)*(B3**2))\n",
    "    d = B0*B2 - B1**2\n",
    "\n",
    "    v0 = (B[0,1] * B[0,2] - B[0,0] * B[1,2]) / (B[0,0] * B[1,1] - B[0,1]**2)\n",
    "    lambda_ = B[2,2] - (B[0,2]**2 + v0 * (B[0,1] * B[0,2] - B[0,0] * B[1,2])) / B[0,0]\n",
    "    print(lambda_)\n",
    "    alpha = np.sqrt(lambda_ / B[0,0])\n",
    "    beta = np.sqrt(lambda_ * B[0,0] / (B[0,0] * B[1,1] - B[0,1]**2))\n",
    "    gamma = -1 * (B[0,1] * alpha * alpha * beta )/ lambda_\n",
    "    u0 = (gamma * v0 / beta) - (B[0,2] * alpha * alpha / lambda_)\n",
    "\n",
    "\n",
    "    # Reconstitute intrinsic matrix\n",
    "    K = np.array([[alpha, gamma, u0],\n",
    "                  [   0,  beta, v0],\n",
    "                  [   0,    0, 1]])\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.94076307e-07  3.39775215e-09  5.00794498e-04]\n",
      " [ 3.39775215e-09 -9.90758043e-07  3.67107740e-04]\n",
      " [ 5.00794498e-04  3.67107740e-04 -9.99999807e-01]]\n",
      "-0.6104119014214286\n",
      "[[783.6130049    2.68288596 505.05112802]\n",
      " [  0.         784.92875339 372.26422834]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "K_refined = intrisicmatrix(H_refined)\n",
    "print(K_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.00490630e-06  3.40566969e-09  5.04300432e-04]\n",
      " [ 3.40566969e-09 -1.00163530e-06  3.71244620e-04]\n",
      " [ 5.04300432e-04  3.71244620e-04 -9.99999804e-01]]\n",
      "-0.6080535685949602\n",
      "[[777.87199322   2.64055711 503.10016721]\n",
      " [  0.         779.14557997 372.34910923]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "K = intrisicmatrix(H)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recover the extrinsic parameters\n",
    "After retrieving the intrinsic matrix, we use both the intrinsic and extrinsic matrix to calculate the corresponding extrinsic matrix( Burger, pag 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_extrinsics(H,K):\n",
    "    # obtain the column vectores from the homography matrix\n",
    "    h0,h1,h2 = H[:,0],H[:,1],H[:,2]\n",
    "    \n",
    "    K_inv = np.linalg.inv(K)\n",
    "    \n",
    "    #norm the term\n",
    "    lambda_ = 1. / np.linalg.norm(np.dot(K_inv, h0))\n",
    "    \n",
    "    r0 = (lambda_ * np.dot(K_inv,h0))\n",
    "    r1 = (lambda_ * np.dot(K_inv,h1))\n",
    "    t =  (lambda_ * np.dot(K_inv,h2)).reshape(3,1)\n",
    "\n",
    "    # since R must be orthogonal\n",
    "    r2 = np.cross(r0,r1)\n",
    "    \n",
    "    # rotation matrix reconstrution\n",
    "    R = np.vstack((r0, r1, r2)).T\n",
    "    \n",
    "    # reorthogonalize the rotation matrix( Zhang, pag 18, Append C)\n",
    "    #(The sense of \"best\" rotation matrix R is in the sense of the smallest Frobenius norm of the difference R-Q)\n",
    "    U,S,Vt = np.linalg.svd(R)\n",
    "    R_ortho = np.dot(U,Vt)\n",
    "    extrinsics = np.hstack((R_ortho, t))\n",
    "    \n",
    "    return extrinsics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Compute the extrinsics based on the intrisincs already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242.44313945776645\n",
      "193.59290124948905\n"
     ]
    }
   ],
   "source": [
    "# list to store the extrinsic matrixes\n",
    "extrinsic_matrices = []\n",
    "\n",
    "\n",
    "# Homographies using the original intrinsic matrix\n",
    "for h, Homograph in enumerate(H):\n",
    "    E = extract_extrinsics(Homograph,K)\n",
    "    extrinsic_matrices.append(E)\n",
    "    \n",
    "    # Projection matrix\n",
    "    P = np.dot(K,E)\n",
    "    \n",
    "    # homogeneous world coordinates\n",
    "    homo_world = np.append(worldcoo[0][:].reshape(patternsize[0]*patternsize[1],3),np.ones((patternsize[0]*patternsize[1],1)),axis = 1) \n",
    "    temp_var = np.dot(homo_world,P.T)\n",
    "    # to euclidean coordinates\n",
    "    actual_coo = to_euclidean(temp_var)\n",
    "    predicted_coo = imagecoo[h]\n",
    "    \n",
    "    # least squares error\n",
    "    ls_error = np.sum(np.abs(actual_coo-predicted_coo)**2)\n",
    "    \n",
    "print(ls_error)    \n",
    "# Homographies using the refined intrinsic matrix    \n",
    "for h, Homograph in enumerate(H_refined):\n",
    "    E = extract_extrinsics(Homograph,K_refined)\n",
    "    extrinsic_matrices.append(E)\n",
    "    \n",
    "    # Projection matrix\n",
    "    P = np.dot(K_refined,E)\n",
    "    # homogeneous world coordinates\n",
    "    homo_world = np.append(worldcoo[0][:].reshape(patternsize[0]*patternsize[1],3),np.ones((patternsize[0]*patternsize[1],1)),axis = 1) \n",
    "    temp_var = np.dot(homo_world,P.T)\n",
    "    # to euclidean coordinates\n",
    "    actual_coo_LM = to_euclidean(temp_var)\n",
    "    predicted_coo = imagecoo[h]\n",
    "    \n",
    "    # least squares error\n",
    "    ls_error = np.sum(np.abs(actual_coo_LM-predicted_coo)**2)\n",
    "\n",
    "\n",
    "\n",
    "print(ls_error)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
